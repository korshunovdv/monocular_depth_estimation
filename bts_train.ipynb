{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9a76c13",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3790c707",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T08:56:20.738965Z",
     "start_time": "2022-05-03T08:56:20.299001Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dvkorshunov/miniconda/envs/bts/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from typing import Any, Dict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd.profiler import profile as profile_ag\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "\n",
    "MB = 1024 * 1024\n",
    "ms = 1000\n",
    "\n",
    "\n",
    "def profile_net(model: nn.Module, *model_input) -> Dict[str, Any]:\n",
    "    \"\"\"A tool that allows you to collect data on the performance of a neural network.\n",
    "    Args:\n",
    "        model: PyTorch model to profile.\n",
    "        model_input: Input to the model (data, parameters, etc.)\n",
    "    Returns:\n",
    "        Information about shape, time, memory and model size.\n",
    "    \"\"\"\n",
    "    with profile(\n",
    "            activities=[ProfilerActivity.CUDA], \n",
    "            record_shapes=True\n",
    "        ) as prof:\n",
    "        with record_function(\"model_inference\"):\n",
    "            model(*model_input)\n",
    "    \n",
    "    print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))\n",
    "    \n",
    "    torch.cuda.synchronize()\n",
    "    with profile_ag(use_cuda=True, profile_memory=True) as prof:\n",
    "        start_time = time.perf_counter()\n",
    "        _, _, _, _, output = model(*model_input)\n",
    "        end_time = time.perf_counter()\n",
    "\n",
    "    return {\n",
    "        'output_shape': output.shape,\n",
    "        'elapsed_time, ms': np.round((end_time - start_time), 4),\n",
    "        'cpu_memory, Mb': np.round(prof.total_average().cpu_memory_usage, 2),\n",
    "        'gpu_memory, Mb': np.round(prof.total_average().cuda_memory_usage, 2),\n",
    "        'model_size, Mb': np.round(\n",
    "            sum(p.numel() * p.element_size() for p in model.parameters()) / MB, 2\n",
    "        ),\n",
    "    }\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84aaf7ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T08:56:20.745935Z",
     "start_time": "2022-05-03T08:56:20.740828Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9424ab95",
   "metadata": {},
   "source": [
    "# BTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da81e86f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T09:04:04.012776Z",
     "start_time": "2022-05-03T09:04:04.006567Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "bts_dir = \"/home/dvkorshunov/mono_depth/monocular_depth_estimation/networks/bts\"\n",
    "bts_torch_dir = bts_dir + \"/pytorch\"\n",
    "bts_pretrains_dir = bts_dir + \"/models\"\n",
    "checkpoint_path = bts_pretrains_dir + \"bts_eigen_v2_pytorch_densenet121/model\"\n",
    "dataset_dir = \"/home/dvkorshunov/mono_depth/monocular_depth_estimation/datasets/datasets/kitti/\"\n",
    "sys.path.insert(1, bts_torch_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e03e191",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T09:04:22.469255Z",
     "start_time": "2022-05-03T09:04:22.459742Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "arguments = (\n",
    "    \"encoder \"\n",
    "    \"data_path \"\n",
    "    \"dataset \"\n",
    "    \"filenames_file \"\n",
    "    \"model_name \"\n",
    "    \"checkpoint_path \"\n",
    "    \"input_height \"\n",
    "    \"input_width \"\n",
    "    \"max_depth \"\n",
    "    \"bts_size \"\n",
    "    \"do_kb_crop\"\n",
    ")\n",
    "Params = namedtuple('Params', arguments)\n",
    "params = Params(\n",
    "    encoder=\"densenet121_bts\",\n",
    "    data_path=dataset_dir,\n",
    "    dataset=\"kitti\",\n",
    "    filenames_file= bts_dir + \"/train_test_inputs/eigen_test_files_with_gt_copy.txt\",\n",
    "    model_name=\"bts_eigen_v2_pytorch_densenet121\",\n",
    "    checkpoint_path=checkpoint_path,\n",
    "    input_height=352,\n",
    "    input_width=1216,\n",
    "    max_depth=80,\n",
    "    bts_size=512,\n",
    "    do_kb_crop=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9592b656",
   "metadata": {},
   "source": [
    "# Load pretrains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "922ffb92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T09:15:07.158239Z",
     "start_time": "2022-05-03T09:15:04.770871Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘/home/dvkorshunov/mono_depth/monocular_depth_estimation/networks/bts/models/bts_eigen_v2_pytorch_densenet121.zip’ already there; not retrieving.\n",
      "Archive:  /home/dvkorshunov/mono_depth/monocular_depth_estimation/networks/bts/models/bts_eigen_v2_pytorch_densenet121.zip\n",
      "  inflating: /home/dvkorshunov/mono_depth/monocular_depth_estimation/networks/bts/models/bts_eigen_v2_pytorch_densenet121/arguments_train_eigen.txt  \n",
      "  inflating: /home/dvkorshunov/mono_depth/monocular_depth_estimation/networks/bts/models/bts_eigen_v2_pytorch_densenet121/bts_eigen_v2_pytorch_densenet121.py  \n",
      "  inflating: /home/dvkorshunov/mono_depth/monocular_depth_estimation/networks/bts/models/bts_eigen_v2_pytorch_densenet121/model  \n"
     ]
    }
   ],
   "source": [
    "! mkdir -p {bts_pretrains_dir}\n",
    "! wget -nc https://cogaplex-bts.s3.ap-northeast-2.amazonaws.com/bts_eigen_v2_pytorch_densenet121.zip -O {bts_pretrains_dir + \"/bts_eigen_v2_pytorch_densenet121.zip\"}\n",
    "! unzip -o {bts_pretrains_dir + \"/bts_eigen_v2_pytorch_densenet121.zip\"} -d {bts_pretrains_dir}    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752f0ee0",
   "metadata": {},
   "source": [
    "# Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "11ce6156",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T09:16:25.122550Z",
     "start_time": "2022-05-03T09:16:24.721431Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/dvkorshunov/mono_depth/monocular_depth_estimation/networks/bts/modelsbts_eigen_v2_pytorch_densenet121/model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-ff9ff0700986>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/bts/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/bts/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/bts/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/dvkorshunov/mono_depth/monocular_depth_estimation/networks/bts/modelsbts_eigen_v2_pytorch_densenet121/model'"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from bts_dataloader import BtsDataLoader\n",
    "from bts import BtsModel\n",
    "\n",
    "def get_num_lines(file_path):\n",
    "    f = open(file_path, 'r')\n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "    return len(lines)\n",
    "\n",
    "dataloader = BtsDataLoader(params, mode=\"test\")\n",
    "    \n",
    "model = BtsModel(params=params)\n",
    "model = torch.nn.DataParallel(model)\n",
    "\n",
    "checkpoint = torch.load(params.checkpoint_path)\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "model.eval()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7985974e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T08:56:21.518936Z",
     "start_time": "2022-05-03T08:56:20.167Z"
    }
   },
   "outputs": [],
   "source": [
    "num_params = sum([np.prod(p.size()) for p in model.parameters()])\n",
    "print(\"Total number of parameters: {}\".format(num_params))\n",
    "\n",
    "num_test_samples = get_num_lines(params.filenames_file)\n",
    "\n",
    "with open(params.filenames_file) as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "print('now testing {} files with {}'.format(num_test_samples, params.checkpoint_path))\n",
    "\n",
    "pred_depths = []\n",
    "pred_8x8s = []\n",
    "pred_4x4s = []\n",
    "pred_2x2s = []\n",
    "pred_1x1s = []\n",
    "\n",
    "start_time = time.time()\n",
    "profile_data = []\n",
    "with torch.no_grad():\n",
    "    for num, sample in enumerate(tqdm(dataloader.data)):\n",
    "        image = Variable(sample['image'].cuda())\n",
    "        focal = Variable(sample['focal'].cuda())\n",
    "        \n",
    "        # warm up\n",
    "        if num == 30:\n",
    "            print(profile_net(model, image, focal))\n",
    "            break\n",
    "        # Predict\n",
    "        lpg8x8, lpg4x4, lpg2x2, reduc1x1, depth_est = model(image, focal)\n",
    "        pred_depths.append(depth_est.cpu().numpy().squeeze())\n",
    "        pred_8x8s.append(lpg8x8[0].cpu().numpy().squeeze())\n",
    "        pred_4x4s.append(lpg4x4[0].cpu().numpy().squeeze())\n",
    "        pred_2x2s.append(lpg2x2[0].cpu().numpy().squeeze())\n",
    "        pred_1x1s.append(reduc1x1[0].cpu().numpy().squeeze())\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print('Elapesed time: %s' % str(elapsed_time))\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a3b8fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T08:56:21.522203Z",
     "start_time": "2022-05-03T08:56:20.167Z"
    }
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# df = pd.DataFrame(profile_data)\n",
    "# df[\"elapsed_time, ms\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b84968",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bts]",
   "language": "python",
   "name": "conda-env-bts-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
